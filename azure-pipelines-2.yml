jobs:
  - job: DeployStreamlitApp
    displayName: 'Deploy Streamlit App to Azure Container Instances'
    pool:
      vmImage: 'ubuntu-latest'

    steps:
      # Set up Python version
      - task: UsePythonVersion@0
        inputs:
          versionSpec: '3.12'
          addToPath: true
          architecture: 'x64'

      # Install required dependencies and Azure CLI tools

      # Authenticate with Azure and create the endpoint
      - task: AzureCLI@2
        inputs:
          azureSubscription: 'nlp_cicd'  # Replace with Azure DevOps service connection
          scriptType: 'bash'
          scriptLocation: 'inlineScript'
          inlineScript: |
            python -m venv venv 
            source venv/bin/activate
            az extension add -n ml --version 2.25.0 --allow-preview
            # Set variables for your storage account and container
            STORAGE_ACCOUNT_NAME="mymlworkstoragecc3b1c0c2"
            CONTAINER_NAME="azureml-blobstore-c729e8d2-9c15-4259-bd04-38cce99054fb"
            BLOB_NAME="LocalUpload/1905f99b50da8d6976b7ba7737c6cbab/compressed_files/multiple_models22.tar.gz"
            DEST_PATH="/home/vsts/work/1/s"  # Local destination path

            # Check if the 'models' directory exists, and create it if not
            #if [ ! -d "$DEST_PATH/models" ]; then
              #echo "Creating models directory inside $DEST_PATH..."
              #mkdir -p $DEST_PATH/models
            #fi

            # Get Storage Account Key
            STORAGE_ACCOUNT_KEY=$(az storage account keys list \
              --resource-group $(ml.resourceGroup) \
              --account-name $STORAGE_ACCOUNT_NAME \
              --query '[0].value' \
              --output tsv)

            # Download the model to your local models directory
            az storage blob download \
              --account-name $STORAGE_ACCOUNT_NAME \
              --account-key $STORAGE_ACCOUNT_KEY \
              --container-name $CONTAINER_NAME \
              --name $BLOB_NAME \
              --file $DEST_PATH/$(basename $BLOB_NAME)

            echo "Model downloaded to: $DEST_PATH"

            # Compress the 'models' directory into a tar.gz archive
            #echo "Compressing the models directory into a tar.gz archive..."
            #tar -czvf $DEST_PATH/model_archive.tar.gz -C $DEST_PATH models  --gzip --best
            #find $DEST_PATH/models -type f | head -n 1500 | tar -czvf $DEST_PATH/model_archive_part1.tar.gz -T - 
            
            #echo "Model compressed to $DEST_PATH/model_archive.tar.gz" 
            #tar -czvf $DEST_PATH/model_archive.tar.gz -C $DEST_PATH models
            #find $DEST_PATH/models -type f | head -n 1500 | tar -czvf $DEST_PATH/model_archive_part1.tar.gz -T -
            #tar -cf - -C $DEST_PATH models | xz -9e -c > $DEST_PATH/model_archive.tar.xz

            
            # Set variables for the model and endpoint
            endpoint_name="streamlit-endpoint2"
            model_uri="azureml://subscriptions/a22eeea6-98d6-4951-a80c-326264b6750f/resourceGroups/my-ml-resource-group/workspaces/my-ml-workspace/datastores/workspaceblobstore/paths/LocalUpload/218cca5e53b658f006af17f0096a8f66/models"

            echo "Current working directory:"
            pwd
            echo "Items in the current workspace:"
            ls -la
            # Create the endpoint
            az ml online-endpoint update --name $endpoint_name \
              --resource-group $(ml.resourceGroup) \
              --workspace-name $(ml.workspace)
      - task: Bash@3
        inputs:
          targetType: 'inline'
          script: |
            # Write your commands here
            
            #!/bin/bash
                  
            # Path to the target file
            FILE_PATH="/opt/az/azcliextensions/ml/azext_mlv2/manual/custom/online_deployment.py"
                  
            # Verify the file exists
            if [ ! -f "$FILE_PATH" ]; then
                echo "File not found: $FILE_PATH"
                exit 1
            fi
                  
            echo "File found: $FILE_PATH"
                  
            # Check if 'debug' variable exists and has a value
            if grep -q "debug =" "$FILE_PATH"; then
                # Extract the value of debug if it has any value
                debug_value=$(grep -oP "(?<=debug = ).*" "$FILE_PATH" | xargs)
                
                # Check if debug_value is a valid function or incomplete statement
                if [[ "$debug_value" == *"("* && "$debug_value" != *")"* ]]; then
                    echo "debug contains an invalid function or incomplete expression: $debug_value"
                    echo "Setting debug to False."
                    debug_value="False"
                fi
                
                if [ -n "$debug_value" ]; then
                    # If 'debug' has a value, copy it to the top of the file and print the value
                    echo "'debug' has a value ($debug_value). Copying it to the top."
                    echo "debug is currently set to: $debug_value"
                    # Copy the line with debug definition to the top
                    sed -i "1i\debug = $debug_value" "$FILE_PATH"
                else
                    # If 'debug' exists but has no value, set it to False and copy it to the top
                    echo "'debug' variable found but has no value. Setting it to 'False' and copying it to the top."
                    echo "debug is currently set to: False"
                    sed -i 's/^debug *= *$/debug = False/' "$FILE_PATH"
                    sed -i '1i\debug = False' "$FILE_PATH"
                fi
            else
                # If 'debug' is not defined, create it and set to False at the top
                echo "'debug' variable not found. Adding 'debug = False' at the top..."
                echo "debug is currently set to: False"
                sed -i '1i\debug = False' "$FILE_PATH"
                echo "'debug = False' has been added globally."
            fi

      - task: AzureCLI@2
        inputs:
          azureSubscription: 'nlp_cicd'  # Replace with Azure DevOps service connection
          scriptType: 'bash'
          scriptLocation: 'inlineScript'
          inlineScript: |
            # Activate virtual environment
            source venv/bin/activate


            # Set variables
            endpoint_name="streamlit-endpoint2"
            #model_name="transformer_cicd"
            #model_version="16"
                  #"azureml://registries/azureml/environments/acft-hf-nlp-gpu/versions/80"
            environment_name="azureml:env_cicd3:1"       #"azureml://locations/eastus/workspaces/ad8d8e3e-4bef-458f-a002-9a776717f887/environments/env_cicd2/versions/1"
            #docker_image="ad8d8e3e4bef458fa0029a776717f887.azurecr.io/azureml/azureml_dd0ec8da2231060248d61ee3eedcb80b"
            scoring_script="score.py"
            condafile="conda.yaml"
            instance_type="ACI"
            instance_count=1
            cpu_allocation=1
            memory_allocation=0.5


            # Confirm Azure CLI login
            echo "Verifying Azure CLI login..."
            az account show > /dev/null 2>&1
            if [ $? -ne 0 ]; then
              echo "Azure CLI is not logged in. Please check your service connection."
              exit 1
            fi


            # Create the deploy.yml file dynamically
            echo "Creating deploy.yml file..."
            cat <<EOF > ./deploy.yml
            \$schema: https://azuremlschemas.azureedge.net/latest/managedOnlineDeployment.schema.json
            name: streamlit-deployment
            endpoint_name: $endpoint_name
            model:multiple_models22.tar.gz
              #path: /home/vsts/work/1/s      #azureml://subscriptions/a22eeea6-98d6-4951-a80c-326264b6750f/resourceGroups/my-ml-resource-group/workspaces/my-ml-workspace/datastores/workspaceblobstore/paths/LocalUpload/218cca5e53b658f006af17f0096a8f66/models
            code_configuration:
              code: ./  # Path to your application code
              scoring_script: $scoring_script  # Entry point of your Streamlit app
            environment: #$environment_name
              conda_file: conda.yaml
              image: mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04
              
                # Path to the Conda environment file
            instance_type: $instance_type  # Use Azure Container Instances
            instance_count: $instance_count  # Number of instances


            EOF


            # Output message to show the generated file
            echo "deploy.yml file has been generated."
            echo "Count of files: $(find . -type f | wc -l)"

            echo "Items in the current workspace:"
            ls -la
            # Deploy the model using the generated deploy.yml
            echo "Creating Azure ML online deployment..."
            az ml online-deployment create --file ./deploy.yml \
              --resource-group $(ml.resourceGroup) \
              --workspace-name $(ml.workspace)