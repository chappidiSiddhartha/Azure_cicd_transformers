
jobs:
 - job: DeployStreamlitApp
   displayName: 'Deploy Streamlit App to Azure Container Instances'
   pool:
     vmImage: 'ubuntu-latest'


   steps:
     # Set up Python version
     - task: UsePythonVersion@0
       inputs:
         versionSpec: '3.12'
         addToPath: true
         architecture: 'x64'


     # Install required dependencies and Azure CLI tools

     # Authenticate with Azure and create the endpoint
     - task: AzureCLI@2
       inputs:
         azureSubscription: 'nlp_cicd'  # Replace with Azure DevOps service connection
         scriptType: 'bash'
         scriptLocation: 'inlineScript'
         inlineScript: |
          python -m venv venv 
          source venv/bin/activate
           az extension add -n ml --version 2.25.0 --allow-preview
           # Set variables for your storage account and container
            STORAGE_ACCOUNT_NAME="mymlworkspace15396310889"
            CONTAINER_NAME="azureml-blobstore-5480ee6b-5d12-4f13-a070-1f6d366ad173"
            BLOB_NAME="LocalUpload/c52c5c2b7e197d2d2154e29cc8a81dd1/models/multiple_models.pkl"
            DEST_PATH="/home/vsts/work/1/s"  # Local destination path

            # Check if the 'models' directory exists, and create it if not
            if [ ! -d "$DEST_PATH/models" ]; then
              echo "Creating models directory inside $DEST_PATH..."
              mkdir -p $DEST_PATH/models
            fi

            # Get Storage Account Key
            STORAGE_ACCOUNT_KEY=$(az storage account keys list \
              --resource-group my-resource-group \
              --account-name $STORAGE_ACCOUNT_NAME \
              --query '[0].value' \
              --output tsv)

            # Download the model to your local models directory
            az storage blob download \
              --account-name $STORAGE_ACCOUNT_NAME \
              --account-key $STORAGE_ACCOUNT_KEY \
              --container-name $CONTAINER_NAME \
              --name $BLOB_NAME \
              --file $DEST_PATH/models/$(basename $BLOB_NAME)

            echo "Model downloaded to: $DEST_PATH/models"

            # Compress the 'models' directory into a tar.gz archive
            echo "Compressing the models directory into a tar.gz archive..."
            tar -czvf $DEST_PATH/model_archive.tar.gz -C $DEST_PATH models

            echo "Model compressed to $DEST_PATH/model_archive.tar.gz"

   
           # Set variables for the model and endpoint
           endpoint_name="streamlit-endpoint1"
           model_uri="azureml://subscriptions/a22eeea6-98d6-4951-a80c-326264b6750f/resourceGroups/my-ml-resource-group/workspaces/my-ml-workspace/datastores/workspaceblobstore/paths/LocalUpload/218cca5e53b658f006af17f0096a8f66/models"

           echo "Current working directory:"
           pwd
           echo "Items in the current workspace:"
           ls -la
           # Create the endpoint
           az ml online-endpoint update --name $endpoint_name \
             --resource-group $(ml.resourceGroup) \
             --workspace-name $(ml.workspace)


     # Create dynamic deploy.yml file and deploy model
     - task: AzureCLI@2
       inputs:
         azureSubscription: 'nlp_cicd'  # Replace with Azure DevOps service connection
         scriptType: 'bash'
         scriptLocation: 'inlineScript'
         inlineScript: |
           # Activate virtual environment
           source venv/bin/activate


           # Set variables
           endpoint_name="streamlit-endpoint1"
           model_name="transformer_cicd"
           model_version="16"
                #"azureml://registries/azureml/environments/acft-hf-nlp-gpu/versions/80"
           environment_name="azureml:env_cicd3:1"       #"azureml://locations/eastus/workspaces/ad8d8e3e-4bef-458f-a002-9a776717f887/environments/env_cicd2/versions/1"
           #docker_image="ad8d8e3e4bef458fa0029a776717f887.azurecr.io/azureml/azureml_dd0ec8da2231060248d61ee3eedcb80b"
           scoring_script="score.py"
           condafile="conda.yaml"
           instance_type="ACI"
           instance_count=1
           cpu_allocation=1
           memory_allocation=0.5


           # Confirm Azure CLI login
           echo "Verifying Azure CLI login..."
           az account show > /dev/null 2>&1
           if [ $? -ne 0 ]; then
             echo "Azure CLI is not logged in. Please check your service connection."
             exit 1
           fi
           echo "Current working directory:"
           pwd
           echo "Items in the current workspace:"
           ls -la
           ls -l .

           # Create the deploy.yml file dynamically
           echo "Creating deploy.yml file..."
           cat <<EOF > ./deploy.yml
           \$schema: https://azuremlschemas.azureedge.net/latest/managedOnlineDeployment.schema.json
           name: streamlit-deployment
           endpoint_name: $endpoint_name
           variables:
            unpack: true
           model:
             path : /home/vsts/work/1/s/models
             unpack: ${{ variables.unpack }}
           code_configuration:
             code: ./  # Path to your application code
             scoring_script: $scoring_script  # Entry point of your Streamlit app
           environment: #$environment_name
             conda_file: conda.yaml
             image: mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04
            
               # Path to the Conda environment file
           instance_type: $instance_type  # Use Azure Container Instances
           instance_count: $instance_count  # Number of instances


           EOF


           # Output message to show the generated file
           echo "deploy.yml file has been generated."


           # Deploy the model using the generated deploy.yml
           echo "Creating Azure ML online deployment..."
           az ml online-deployment create --file ./deploy.yml \
             --resource-group $(ml.resourceGroup) \
             --workspace-name $(ml.workspace)